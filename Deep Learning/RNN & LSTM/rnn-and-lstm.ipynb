{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:30:31.819112Z","iopub.execute_input":"2025-06-23T19:30:31.819770Z","iopub.status.idle":"2025-06-23T19:30:31.823955Z","shell.execute_reply.started":"2025-06-23T19:30:31.819742Z","shell.execute_reply":"2025-06-23T19:30:31.823212Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:31:17.021125Z","iopub.execute_input":"2025-06-23T19:31:17.021430Z","iopub.status.idle":"2025-06-23T19:31:17.024804Z","shell.execute_reply.started":"2025-06-23T19:31:17.021410Z","shell.execute_reply":"2025-06-23T19:31:17.024137Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Build Recurrent Neural Network (RNN)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import Dense, SimpleRNN, Embedding\n\n# Import the Tokenizer class from the text module in TensorFlow Keras preprocessing\n# This class is used to vectorize a text corpus, by turning each text into either a sequence of integers\n# (each integer being the index of a token in a dictionary) or into a vector where the coefficient(s)\n# for each token could be binary, based on word count, based on tf-idf...\nfrom tensorflow.keras.preprocessing.text import Tokenizer\n\n# Import the pad_sequences function from the sequence module in TensorFlow Keras preprocessing\n# This function is used to ensure that all sequences in a list have the same length,\n# by padding shorter sequences with a specified value (by default 0) or truncating longer sequences\n# to a specified length.\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:31:19.171575Z","iopub.execute_input":"2025-06-23T19:31:19.172082Z","iopub.status.idle":"2025-06-23T19:31:19.176195Z","shell.execute_reply.started":"2025-06-23T19:31:19.172061Z","shell.execute_reply":"2025-06-23T19:31:19.175559Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Sample Data for Training ","metadata":{}},{"cell_type":"code","source":" \n# Sample data\nsentences = [\n    \"Machine learning algorithms are powerful tools.\"\n    \"I enjoy exploring new algorithms.\"\n    \"Learning about AI is captivating.\"\n    \"Deep learning models can be complex.\"\n    \"I love understanding how neural networks work.\"\n    \"The field of data science is evolving rapidly.\"\n    \"I find artificial intelligence intriguing.\"\n    \"Studying computer vision is exciting.\"\n    \"Natural language processing is a fascinating domain.\"\n    \"I enjoy coding in Python for data science projects.\"\n    \"Building models is a creative process.\"\n    \"I love experimenting with different machine learning techniques.\"\n    \"The potential of AI to transform industries is amazing.\"\n    \"I enjoy staying updated with the latest tech trends.\"\n    \"Learning about reinforcement learning is interesting.\"\n    \"I find predictive modeling to be very useful.\"\n    \"I love solving problems with data analysis.\"\n    \"Data preprocessing is a crucial step in machine learning.\"\n    \"I enjoy reading research papers on deep learning.\"\n    \"I find optimization techniques fascinating.\"\n    \"Understanding algorithms helps in developing better solutions.\"\n    \"I love the challenge of debugging code.\"\n    \"Machine learning applications are diverse and impactful.\"\n    \"I enjoy collaborating with others on tech projects.\"\n    \"Learning new programming languages is fun.\"\n    \"I love working with large datasets.\"\n    \"I find feature engineering to be an art.\"\n    \"Model evaluation is an essential part of machine learning.\"\n    \"I enjoy attending tech conferences.\"\n    \"Learning about big data technologies is exciting.\"\n    \"I love experimenting with neural network architectures.\"\n    \"I find the theory behind machine learning algorithms interesting.\"\n    \"I enjoy visualizing data insights.\"\n    \"Machine learning models can make accurate predictions.\"\n    \"I love the creativity involved in data storytelling.\"\n    \"I find unsupervised learning techniques intriguing.\"\n    \"I enjoy automating tasks with AI.\"\n    \"Learning about AI ethics is important.\"\n    \"I love the problem-solving aspect of machine learning.\"\n    \"I find cloud computing technologies fascinating.\"\n    \"I enjoy using machine learning for real-world applications.\"\n    \"I love experimenting with different data preprocessing techniques.\"\n    \"I find transfer learning to be a powerful approach.\"\n    \"I enjoy working on machine learning projects.\"\n    \"Learning about data privacy is crucial.\"\n    \"I love the innovation happening in the AI field.\"\n    \"I find data visualization tools useful.\"\n    \"I enjoy testing and validating machine learning models.\"\n    \"I love discovering new machine learning applications.\"\n    \"I find ensemble methods to be effective.\"\n    \"I enjoy learning from data.\"\n    \"Machine learning can provide valuable insights.\"\n    \"I love the interdisciplinary nature of AI.\"\n    \"I find recommendation systems interesting.\"\n    \"I enjoy participating in hackathons.\"\n    \"Learning about neural networks is fascinating.\"\n    \"I love the potential of AI to solve complex problems.\"\n    \"I find sentiment analysis intriguing.\"\n    \"I enjoy implementing machine learning algorithms.\"\n    \"I love the excitement of discovering patterns in data.\"\n    \"I find time series analysis challenging.\"\n    \"I enjoy exploring different types of data.\"\n    \"Machine learning is transforming various industries.\"\n    \"I love working on predictive analytics.\"\n    \"I find anomaly detection to be useful.\"\n    \"I enjoy studying the mathematics behind machine learning.\"\n    \"I love the hands-on experience of building models.\"\n    \"I find clustering techniques interesting.\"\n    \"I enjoy exploring open-source machine learning libraries.\"\n    \"Machine learning can automate complex tasks.\"\n    \"I love the flexibility of machine learning models.\"\n    \"I find computer vision applications fascinating.\"\n    \"I enjoy solving real-world problems with AI.\"\n    \"I love the continuous learning aspect of AI.\"\n    \"I find reinforcement learning to be challenging.\"\n    \"I enjoy experimenting with hyperparameter tuning.\"\n    \"Machine learning can improve decision-making processes.\"\n    \"I love the creativity involved in feature selection.\"\n    \"I find generative models to be fascinating.\"\n    \"I enjoy reading about the latest AI advancements.\"\n    \"Machine learning can enhance user experiences.\"\n    \"I love the diversity of machine learning applications.\"\n    \"I find natural language generation intriguing.\"\n    \"I enjoy working with text data.\"\n    \"Machine learning can optimize business processes.\"\n    \"I love the innovation in AI research.\"\n    \"I find the concept of machine learning interpretability interesting.\"\n    \"I enjoy creating machine learning workflows.\"\n    \"Machine learning can uncover hidden patterns.\"\n    \"I love the impact of AI on society.\"\n    \"I find deep reinforcement learning fascinating.\"\n    \"I enjoy developing custom machine learning solutions.\"\n    \"Machine learning can improve customer experiences.\"\n    \"I love the potential of AI in healthcare.\"\n    \"I find the scalability of machine learning models intriguing.\"\n    \"I enjoy applying machine learning to finance.\"\n    \"Machine learning can enhance security measures.\"\n    \"I love the possibilities of AI in creative industries.\"\n    \"I find the ethical implications of AI important.\"\n    \"I enjoy sharing knowledge about machine learning.\"\n    \"This Free Advance AI Course that is helping alot of students to learn the concepts of AI and provides the detailed guideline on how to learn AI. This course enables the students to make their own projects. Updates them with the state of the art technologies and provide all the necessary knowlegde so that they should not be dependend on anyone to be able to learn anything.\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:31:22.244685Z","iopub.execute_input":"2025-06-23T19:31:22.245329Z","iopub.status.idle":"2025-06-23T19:31:22.250863Z","shell.execute_reply.started":"2025-06-23T19:31:22.245307Z","shell.execute_reply":"2025-06-23T19:31:22.250131Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Tokenization and Preprocessing of the Data \nText Preprocessing Overview\n\n**Tokenizer**: Converts text into sequences of integers, assigning a unique index to each word.\n\n**fit_on_texts**: Updates vocabulary based on input text.\n\n**texts_to_sequences**: Converts texts to integer sequences.\nSequences and Padding:\n\n**N-gram Sequences**: Created from text sequences for language modeling.\n\n**Padding**: Ensures all sequences are the same length using pad_sequences, with zeros added at the beginning if necessary.\n\n**Total Words**: Represents the number of unique words plus one for padding, useful for setting model output size.\n\n","metadata":{}},{"cell_type":"code","source":"# --------------------------- TEXT TOKENIZATION ---------------------------\n\n# Step 1: Initialize the tokenizer\n# The Tokenizer helps convert words into numerical values (word → index)\ntokenizer = Tokenizer()\n\n# Step 2: Fit the tokenizer on your list of sentences\n# This builds a vocabulary (word index) based on the frequency of words\ntokenizer.fit_on_texts(sentences)\n\n# Step 3: Get the total number of unique words\n# We add 1 to include a padding token (used later for sequence alignment)\ntotal_words = len(tokenizer.word_index) + 1\nprint(\"Total Unique Words (including padding):\", total_words)\nprint(\"Word Index (word to number mapping):\", tokenizer.word_index)\n\n# ------------------------ GENERATE TRAINING SEQUENCES ------------------------\n\n# Step 4: Create a list to hold our input sequences\ninput_sequences = []\n\n# Step 5: For each sentence, create sequences of word indices\nfor line in sentences:\n    # Convert each sentence into a list of integers based on the tokenizer\n    token_list = tokenizer.texts_to_sequences([line])[0]\n    \n    # Step 6: Create n-gram sequences\n    # For a sentence like [2, 4, 6], we create:\n    # [2, 4], [2, 4, 6]\n    for i in range(1, len(token_list)):\n        n_gram_sequence = token_list[:i+1]  # slice the list up to the ith token\n        input_sequences.append(n_gram_sequence)  # add to our list of sequences\n\n# ------------------------ PADDING SEQUENCES ------------------------\n\n# Step 7: Find the length of the longest sequence\n# This helps in standardizing the length of all sequences\nmax_sequence_len = max([len(x) for x in input_sequences])\n\n# Step 8: Pad all sequences so they have the same length\n# 'pre' padding adds zeros to the beginning of shorter sequences\ninput_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n\n# Step 9: Print the padded sequences to understand the final input\nprint(\"Padded Input Sequences:\\n\", input_sequences)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:31:27.272178Z","iopub.execute_input":"2025-06-23T19:31:27.272860Z","iopub.status.idle":"2025-06-23T19:31:27.302905Z","shell.execute_reply.started":"2025-06-23T19:31:27.272836Z","shell.execute_reply":"2025-06-23T19:31:27.302184Z"}},"outputs":[{"name":"stdout","text":"Total Unique Words (including padding): 254\nWord Index (word to number mapping): {'i': 1, 'learning': 2, 'machine': 3, 'the': 4, 'enjoy': 5, 'love': 6, 'find': 7, 'of': 8, 'ai': 9, 'is': 10, 'to': 11, 'data': 12, 'with': 13, 'in': 14, 'can': 15, 'be': 16, 'about': 17, 'models': 18, 'on': 19, 'fascinating': 20, 'algorithms': 21, 'intriguing': 22, 'techniques': 23, 'interesting': 24, 'applications': 25, 'a': 26, 'projects': 27, 'experimenting': 28, 'and': 29, 'working': 30, 'exploring': 31, 'new': 32, 'deep': 33, 'complex': 34, 'neural': 35, 'different': 36, 'potential': 37, 'industries': 38, 'tech': 39, 'reinforcement': 40, 'useful': 41, 'solving': 42, 'problems': 43, 'analysis': 44, 'technologies': 45, 'learn': 46, 'are': 47, 'powerful': 48, 'tools': 49, 'understanding': 50, 'how': 51, 'networks': 52, 'field': 53, 'science': 54, 'studying': 55, 'computer': 56, 'vision': 57, 'exciting': 58, 'natural': 59, 'language': 60, 'for': 61, 'building': 62, 'creative': 63, 'latest': 64, 'predictive': 65, 'preprocessing': 66, 'crucial': 67, 'reading': 68, 'research': 69, 'developing': 70, 'solutions': 71, 'feature': 72, 'an': 73, 'art': 74, 'behind': 75, 'insights': 76, 'make': 77, 'creativity': 78, 'involved': 79, 'tasks': 80, 'important': 81, 'aspect': 82, 'real': 83, 'world': 84, 'innovation': 85, 'discovering': 86, 'provide': 87, 'patterns': 88, 'challenging': 89, 'improve': 90, 'processes': 91, 'enhance': 92, 'experiences': 93, 'this': 94, 'course': 95, 'that': 96, 'students': 97, 'captivating': 98, 'work': 99, 'evolving': 100, 'rapidly': 101, 'artificial': 102, 'intelligence': 103, 'processing': 104, 'domain': 105, 'coding': 106, 'python': 107, 'process': 108, 'transform': 109, 'amazing': 110, 'staying': 111, 'updated': 112, 'trends': 113, 'modeling': 114, 'very': 115, 'step': 116, 'papers': 117, 'optimization': 118, 'helps': 119, 'better': 120, 'challenge': 121, 'debugging': 122, 'code': 123, 'diverse': 124, 'impactful': 125, 'collaborating': 126, 'others': 127, 'programming': 128, 'languages': 129, 'fun': 130, 'large': 131, 'datasets': 132, 'engineering': 133, 'model': 134, 'evaluation': 135, 'essential': 136, 'part': 137, 'attending': 138, 'conferences': 139, 'big': 140, 'network': 141, 'architectures': 142, 'theory': 143, 'visualizing': 144, 'accurate': 145, 'predictions': 146, 'storytelling': 147, 'unsupervised': 148, 'automating': 149, 'ethics': 150, 'problem': 151, 'cloud': 152, 'computing': 153, 'using': 154, 'transfer': 155, 'approach': 156, 'privacy': 157, 'happening': 158, 'visualization': 159, 'testing': 160, 'validating': 161, 'ensemble': 162, 'methods': 163, 'effective': 164, 'from': 165, 'valuable': 166, 'interdisciplinary': 167, 'nature': 168, 'recommendation': 169, 'systems': 170, 'participating': 171, 'hackathons': 172, 'solve': 173, 'sentiment': 174, 'implementing': 175, 'excitement': 176, 'time': 177, 'series': 178, 'types': 179, 'transforming': 180, 'various': 181, 'analytics': 182, 'anomaly': 183, 'detection': 184, 'mathematics': 185, 'hands': 186, 'experience': 187, 'clustering': 188, 'open': 189, 'source': 190, 'libraries': 191, 'automate': 192, 'flexibility': 193, 'continuous': 194, 'hyperparameter': 195, 'tuning': 196, 'decision': 197, 'making': 198, 'selection': 199, 'generative': 200, 'advancements': 201, 'user': 202, 'diversity': 203, 'generation': 204, 'text': 205, 'optimize': 206, 'business': 207, 'concept': 208, 'interpretability': 209, 'creating': 210, 'workflows': 211, 'uncover': 212, 'hidden': 213, 'impact': 214, 'society': 215, 'custom': 216, 'customer': 217, 'healthcare': 218, 'scalability': 219, 'applying': 220, 'finance': 221, 'security': 222, 'measures': 223, 'possibilities': 224, 'ethical': 225, 'implications': 226, 'sharing': 227, 'knowledge': 228, 'free': 229, 'advance': 230, 'helping': 231, 'alot': 232, 'concepts': 233, 'provides': 234, 'detailed': 235, 'guideline': 236, 'enables': 237, 'their': 238, 'own': 239, 'updates': 240, 'them': 241, 'state': 242, 'all': 243, 'necessary': 244, 'knowlegde': 245, 'so': 246, 'they': 247, 'should': 248, 'not': 249, 'dependend': 250, 'anyone': 251, 'able': 252, 'anything': 253}\nPadded Input Sequences:\n [[  0   0   0 ...   0   3   2]\n [  0   0   0 ...   3   2  21]\n [  0   0   0 ...   2  21  47]\n ...\n [  0   0   3 ...  16 252  11]\n [  0   3   2 ... 252  11  46]\n [  3   2  21 ...  11  46 253]]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Data Preparation ","metadata":{}},{"cell_type":"code","source":"# ------------------------- SPLITTING INPUTS AND LABELS -------------------------\n\n# Step 1: Inputs (X) — all tokens in the sequence *except* the last one\n# For example, if a padded sequence is [0, 2, 4, 6]\n# X will be [0, 2, 4] → the words used as input\nX = input_sequences[:, :-1]  # All columns except the last one\nprint(\"Input Data (X):\", X)\n\n# Step 2: Labels (y) — the *last* token in the sequence\n# For the same example [0, 2, 4, 6]\n# y will be 6 → the word we want the model to predict\ny = input_sequences[:, -1]  # Only the last column\nprint(\"Labels (y):\", y)\n\n# ------------------------- ONE-HOT ENCODING LABELS -------------------------\n\n# Step 3: Convert the label values (word indices) into one-hot vectors\n# This step is needed because neural networks don't work directly with labels like 6 or 10\n# One-hot encoding turns label 6 into [0, 0, 0, 0, 0, 0, 1, 0, ...] — a vector with a 1 at the 6th index\n# total_words is used to ensure the one-hot vector has the correct length (same as vocabulary size)\ny = tf.keras.utils.to_categorical(y, num_classes=total_words)\n# print(\"One-hot Encoded Labels (y):\", y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:31:31.588894Z","iopub.execute_input":"2025-06-23T19:31:31.589446Z","iopub.status.idle":"2025-06-23T19:31:31.596103Z","shell.execute_reply.started":"2025-06-23T19:31:31.589421Z","shell.execute_reply":"2025-06-23T19:31:31.595363Z"}},"outputs":[{"name":"stdout","text":"Input Data (X): [[  0   0   0 ...   0   0   3]\n [  0   0   0 ...   0   3   2]\n [  0   0   0 ...   3   2  21]\n ...\n [  0   0   3 ...  11  16 252]\n [  0   3   2 ...  16 252  11]\n [  3   2  21 ... 252  11  46]]\nLabels (y): [  2  21  47  48  49   1   5  31  32  21   2  17   9  10  98  33   2  18\n  15  16  34   1   6  50  51  35  52  99   4  53   8  12  54  10 100 101\n   1   7 102 103  22  55  56  57  10  58  59  60 104  10  26  20 105   1\n   5 106  14 107  61  12  54  27  62  18  10  26  63 108   1   6  28  13\n  36   3   2  23   4  37   8   9  11 109  38  10 110   1   5 111 112  13\n   4  64  39 113   2  17  40   2  10  24   1   7  65 114  11  16 115  41\n   1   6  42  43  13  12  44  12  66  10  26  67 116  14   3   2   1   5\n  68  69 117  19  33   2   1   7 118  23  20  50  21 119  14  70 120  71\n   1   6   4 121   8 122 123   3   2  25  47 124  29 125   1   5 126  13\n 127  19  39  27   2  32 128 129  10 130   1   6  30  13 131 132   1   7\n  72 133  11  16  73  74 134 135  10  73 136 137   8   3   2   1   5 138\n  39 139   2  17 140  12  45  10  58   1   6  28  13  35 141 142   1   7\n   4 143  75   3   2  21  24   1   5 144  12  76   3   2  18  15  77 145\n 146   1   6   4  78  79  14  12 147   1   7 148   2  23  22   1   5 149\n  80  13   9   2  17   9 150  10  81   1   6   4 151  42  82   8   3   2\n   1   7 152 153  45  20   1   5 154   3   2  61  83  84  25   1   6  28\n  13  36  12  66  23   1   7 155   2  11  16  26  48 156   1   5  30  19\n   3   2  27   2  17  12 157  10  67   1   6   4  85 158  14   4   9  53\n   1   7  12 159  49  41   1   5 160  29 161   3   2  18   1   6  86  32\n   3   2  25   1   7 162 163  11  16 164   1   5   2 165  12   3   2  15\n  87 166  76   1   6   4 167 168   8   9   1   7 169 170  24   1   5 171\n  14 172   2  17  35  52  10  20   1   6   4  37   8   9  11 173  34  43\n   1   7 174  44  22   1   5 175   3   2  21   1   6   4 176   8  86  88\n  14  12   1   7 177 178  44  89   1   5  31  36 179   8  12   3   2  10\n 180 181  38   1   6  30  19  65 182   1   7 183 184  11  16  41   1   5\n  55   4 185  75   3   2   1   6   4 186  19 187   8  62  18   1   7 188\n  23  24   1   5  31 189 190   3   2 191   3   2  15 192  34  80   1   6\n   4 193   8   3   2  18   1   7  56  57  25  20   1   5  42  83  84  43\n  13   9   1   6   4 194   2  82   8   9   1   7  40   2  11  16  89   1\n   5  28  13 195 196   3   2  15  90 197 198  91   1   6   4  78  79  14\n  72 199   1   7 200  18  11  16  20   1   5  68  17   4  64   9 201   3\n   2  15  92 202  93   1   6   4 203   8   3   2  25   1   7  59  60 204\n  22   1   5  30  13 205  12   3   2  15 206 207  91   1   6   4  85  14\n   9  69   1   7   4 208   8   3   2 209  24   1   5 210   3   2 211   3\n   2  15 212 213  88   1   6   4 214   8   9  19 215   1   7  33  40   2\n  20   1   5  70 216   3   2  71   3   2  15  90 217  93   1   6   4  37\n   8   9  14 218   1   7   4 219   8   3   2  18  22   1   5 220   3   2\n  11 221   3   2  15  92 222 223   1   6   4 224   8   9  14  63  38   1\n   7   4 225 226   8   9  81   1   5 227 228  17   3   2  94 229 230   9\n  95  96  10 231 232   8  97  11  46   4 233   8   9  29 234   4 235 236\n  19  51  11  46   9  94  95 237   4  97  11  77 238 239  27 240 241  13\n   4 242   8   4  74  45  29  87 243   4 244 245 246  96 247 248 249  16\n 250  19 251  11  16 252  11  46 253]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## **Defining the Model Architecture:**\n\n**Sequential Model:** A linear stack of layers.\n\n**Embedding Layer:** Converts word indices to dense vectors, helping the model understand word relationships.\n\n**SimpleRNN Layer:** Processes the sequence data and captures temporal dependencies.\n\nDense Layer with Softmax: Outputs a probability distribution over the total words, predicting the next word in the sequence.","metadata":{}},{"cell_type":"code","source":"# ------------------------- DEFINING THE RNN MODEL -------------------------\n\n# Import necessary modules\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n\n# Step 1: Define a Sequential model\n# Sequential means layers are added one after the other in a linear stack\nmodel = Sequential([\n\n    # Step 2: Embedding Layer\n    # Converts each word index into a fixed-size dense vector (word embedding)\n    # total_words: size of the vocabulary (number of unique words + 1 for padding)\n    # 10: size of the embedding vector for each word\n    # input_length: length of each input sequence (we use max_sequence_len - 1 \n    # because the last word in each sequence is used as the label, not input)\n    Embedding(input_dim=total_words, output_dim=10, input_length=max_sequence_len - 1),\n\n    # Step 3: Simple RNN Layer\n    # Processes the sequence of embeddings, one timestep at a time\n    # 30 units means the RNN will output a 30-dimensional vector after reading the input sequence\n    SimpleRNN(units=100),\n\n    # Step 4: Output Layer\n    # A dense (fully connected) layer with softmax activation\n    # total_words: number of output neurons, equal to vocabulary size\n    # softmax: ensures output is a probability distribution across all possible next words\n    Dense(units=total_words, activation='softmax')\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:31:39.857502Z","iopub.execute_input":"2025-06-23T19:31:39.858077Z","iopub.status.idle":"2025-06-23T19:31:39.868555Z","shell.execute_reply.started":"2025-06-23T19:31:39.858056Z","shell.execute_reply":"2025-06-23T19:31:39.867983Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# ------------------------- COMPILE THE MODEL -------------------------\n\n# Compile the model before training\n# This step configures the model’s learning process\n\nmodel.compile(\n    loss='categorical_crossentropy',  # Loss function for multi-class classification\n    optimizer='adam',                 # Adam optimizer adjusts the weights efficiently during training\n    metrics=['accuracy']              # Track accuracy as a metric while training\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:31:43.089048Z","iopub.execute_input":"2025-06-23T19:31:43.089613Z","iopub.status.idle":"2025-06-23T19:31:43.107637Z","shell.execute_reply.started":"2025-06-23T19:31:43.089591Z","shell.execute_reply":"2025-06-23T19:31:43.107109Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# ------------------------- TRAIN THE MODEL -------------------------\n\n# Train the model on the input data (X) and labels (y)\n# This is where the model learns patterns in the word sequences\n\nmodel.fit(\n    X,          # Input data: sequences of words (excluding the last word)\n    y,          # Labels: the next word to predict (in one-hot format)\n    epochs=100,  # Number of times the model sees the entire training dataset\n    verbose=1   # Display progress bar and training info while training\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:31:45.957610Z","iopub.execute_input":"2025-06-23T19:31:45.957879Z","iopub.status.idle":"2025-06-23T19:34:10.528930Z","shell.execute_reply.started":"2025-06-23T19:31:45.957860Z","shell.execute_reply":"2025-06-23T19:34:10.528355Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1750707108.575339      98 service.cc:148] XLA service 0x7bbf20006260 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1750707108.575876      98 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1750707108.919813      98 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 3/24\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.0191 - loss: 5.5418","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1750707110.009240      98 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - accuracy: 0.0100 - loss: 5.5473\nEpoch 2/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.0145 - loss: 5.5211\nEpoch 3/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.0456 - loss: 5.3114\nEpoch 4/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.0699 - loss: 4.8456\nEpoch 5/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.0940 - loss: 4.6337\nEpoch 6/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.0995 - loss: 4.6551\nEpoch 7/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.0925 - loss: 4.6539\nEpoch 8/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.0984 - loss: 4.5767\nEpoch 9/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.0749 - loss: 4.5447\nEpoch 10/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.0889 - loss: 4.4909\nEpoch 11/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.1412 - loss: 4.3353\nEpoch 12/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.1749 - loss: 4.2558\nEpoch 13/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.1800 - loss: 4.1929\nEpoch 14/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.2136 - loss: 4.0101\nEpoch 15/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.2307 - loss: 3.8325\nEpoch 16/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.2342 - loss: 3.7089\nEpoch 17/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.2633 - loss: 3.5683\nEpoch 18/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.2493 - loss: 3.4579\nEpoch 19/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.3183 - loss: 3.3600\nEpoch 20/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.3074 - loss: 3.1806\nEpoch 21/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.3368 - loss: 3.0432\nEpoch 22/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.3344 - loss: 2.9212\nEpoch 23/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.3615 - loss: 2.8065\nEpoch 24/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.3860 - loss: 2.7140\nEpoch 25/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.4073 - loss: 2.5351\nEpoch 26/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.4253 - loss: 2.4182\nEpoch 27/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.4510 - loss: 2.3136\nEpoch 28/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.4521 - loss: 2.3064\nEpoch 29/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.4447 - loss: 2.2165\nEpoch 30/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5188 - loss: 2.0860\nEpoch 31/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5011 - loss: 2.0862\nEpoch 32/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5394 - loss: 1.9605\nEpoch 33/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5523 - loss: 1.9025\nEpoch 34/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6053 - loss: 1.7656\nEpoch 35/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6331 - loss: 1.7270\nEpoch 36/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6588 - loss: 1.6106\nEpoch 37/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.6587 - loss: 1.5907\nEpoch 38/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6883 - loss: 1.4408\nEpoch 39/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6988 - loss: 1.4072\nEpoch 40/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7289 - loss: 1.3089\nEpoch 41/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7726 - loss: 1.1976\nEpoch 42/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7858 - loss: 1.1668\nEpoch 43/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8029 - loss: 1.1159\nEpoch 44/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7945 - loss: 1.1194\nEpoch 45/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8036 - loss: 1.0851\nEpoch 46/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8368 - loss: 0.9433\nEpoch 47/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8683 - loss: 0.8790\nEpoch 48/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8546 - loss: 0.8948\nEpoch 49/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8799 - loss: 0.8203\nEpoch 50/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8734 - loss: 0.7973\nEpoch 51/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9082 - loss: 0.7383\nEpoch 52/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9180 - loss: 0.6992\nEpoch 53/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9147 - loss: 0.6518\nEpoch 54/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9425 - loss: 0.6352\nEpoch 55/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9487 - loss: 0.5867\nEpoch 56/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9488 - loss: 0.5947\nEpoch 57/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9516 - loss: 0.5573\nEpoch 58/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9753 - loss: 0.5071\nEpoch 59/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9637 - loss: 0.4896\nEpoch 60/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9739 - loss: 0.4667\nEpoch 61/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9721 - loss: 0.4350\nEpoch 62/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9841 - loss: 0.4198\nEpoch 63/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9846 - loss: 0.4025\nEpoch 64/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9840 - loss: 0.3891\nEpoch 65/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9928 - loss: 0.3371\nEpoch 66/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9933 - loss: 0.3429\nEpoch 67/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9827 - loss: 0.3314\nEpoch 68/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9693 - loss: 0.4017\nEpoch 69/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9616 - loss: 0.4656\nEpoch 70/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9772 - loss: 0.3814\nEpoch 71/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9674 - loss: 0.4378\nEpoch 72/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9576 - loss: 0.4214\nEpoch 73/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9784 - loss: 0.3544\nEpoch 74/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9862 - loss: 0.3386\nEpoch 75/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9790 - loss: 0.3170\nEpoch 76/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9943 - loss: 0.2724\nEpoch 77/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9947 - loss: 0.2688\nEpoch 78/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9925 - loss: 0.2724\nEpoch 79/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9948 - loss: 0.2539\nEpoch 80/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9774 - loss: 0.3310\nEpoch 81/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9948 - loss: 0.2619\nEpoch 82/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9694 - loss: 0.3073\nEpoch 83/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9895 - loss: 0.2708\nEpoch 84/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9892 - loss: 0.2559\nEpoch 85/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9978 - loss: 0.2175\nEpoch 86/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9961 - loss: 0.1927\nEpoch 87/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9638 - loss: 0.3044\nEpoch 88/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9950 - loss: 0.2322\nEpoch 89/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9954 - loss: 0.2054\nEpoch 90/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9993 - loss: 0.1829\nEpoch 91/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1608\nEpoch 92/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9990 - loss: 0.1455\nEpoch 93/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9995 - loss: 0.1366\nEpoch 94/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.1231\nEpoch 95/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1272\nEpoch 96/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1180\nEpoch 97/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.1105\nEpoch 98/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.1060\nEpoch 99/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.1005\nEpoch 100/100\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0973\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7bbffeff5390>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"## **Next Word Prediction:**\n\n**Seed Text Conversion:** The input text (seed_text) is converted to a sequence of integers using the tokenizer.\n\n**Padding:** The integer sequence is padded to ensure it matches the model's expected input length.\n\n**Prediction:** The model predicts the probability of each word in the vocabulary as the next word.\n\n**Selection and Update:** The word with the highest probability is selected, converted back to a word, and appended to the seed text.\n\n**Iterative Prediction:** This process can be repeated for a specified number of words (next_words).","metadata":{}},{"cell_type":"code","source":"# ------------------------- PREDICT NEXT WORD(S) FUNCTION -------------------------\n\n# Define a function to predict the next word(s) given some seed text\n# seed_text: starting words provided by the user\n# next_words: number of words to predict and append\n\ndef predict_next_word(seed_text, next_words=1):\n    for _ in range(next_words):\n        # Step 1: Convert the seed text (string) into a list of integers (tokens)\n        # This is necessary because our model was trained on sequences of numbers, not raw text\n        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n\n        # Step 2: Pad the token list to ensure it matches the model's input size\n        # This pads the sequence from the front with zeros if it's shorter than required length\n        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n\n        # Step 3: Predict the probabilities of the next word using the trained model\n        # The output is a probability distribution over all words in the vocabulary\n        predicted = model.predict(token_list, verbose=0)\n\n        # Step 4: Find the index of the word with the highest probability\n        # This is the model's best guess for the next word\n        predicted_word_index = np.argmax(predicted, axis=-1)[0]\n\n        # Step 5: Convert the predicted index back to the actual word using the tokenizer's index\n        predicted_word = tokenizer.index_word[predicted_word_index]\n\n        # Step 6: Add the predicted word to the original seed text\n        # This will help predict the next word in the next loop (if next_words > 1)\n        seed_text += \" \" + predicted_word\n\n    # Step 7: Return the final generated text\n    return seed_text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:35:41.717109Z","iopub.execute_input":"2025-06-23T19:35:41.717692Z","iopub.status.idle":"2025-06-23T19:35:41.722666Z","shell.execute_reply.started":"2025-06-23T19:35:41.717673Z","shell.execute_reply":"2025-06-23T19:35:41.721850Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Test the prediction function with a sample input\nprint(predict_next_word(\"machine learning i enjoy about machine learning\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:36:28.620904Z","iopub.execute_input":"2025-06-23T19:36:28.621592Z","iopub.status.idle":"2025-06-23T19:36:28.708504Z","shell.execute_reply.started":"2025-06-23T19:36:28.621567Z","shell.execute_reply":"2025-06-23T19:36:28.707926Z"}},"outputs":[{"name":"stdout","text":"machine learning i enjoy about machine learning to\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# Building a Long Short-Term Memory (LSTM)","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, Embedding\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:36:38.913723Z","iopub.execute_input":"2025-06-23T19:36:38.914401Z","iopub.status.idle":"2025-06-23T19:36:38.918961Z","shell.execute_reply.started":"2025-06-23T19:36:38.914374Z","shell.execute_reply":"2025-06-23T19:36:38.918134Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"## Sample data\n","metadata":{}},{"cell_type":"code","source":"# Sample data\nsentences = [\n    \"Machine learning algorithms are powerful tools.\"\n    \"I enjoy exploring new algorithms.\"\n    \"Learning about AI is captivating.\"\n    \"Deep learning models can be complex.\"\n    \"I love understanding how neural networks work.\"\n    \"The field of data science is evolving rapidly.\"\n    \"I find artificial intelligence intriguing.\"\n    \"Studying computer vision is exciting.\"\n    \"Natural language processing is a fascinating domain.\"\n    \"I enjoy coding in Python for data science projects.\"\n    \"Building models is a creative process.\"\n    \"I love experimenting with different machine learning techniques.\"\n    \"The potential of AI to transform industries is amazing.\"\n    \"I enjoy staying updated with the latest tech trends.\"\n    \"Learning about reinforcement learning is interesting.\"\n    \"I find predictive modeling to be very useful.\"\n    \"I love solving problems with data analysis.\"\n    \"Data preprocessing is a crucial step in machine learning.\"\n    \"I enjoy reading research papers on deep learning.\"\n    \"I find optimization techniques fascinating.\"\n    \"Understanding algorithms helps in developing better solutions.\"\n    \"I love the challenge of debugging code.\"\n    \"Machine learning applications are diverse and impactful.\"\n    \"I enjoy collaborating with others on tech projects.\"\n    \"Learning new programming languages is fun.\"\n    \"I love working with large datasets.\"\n    \"I find feature engineering to be an art.\"\n    \"Model evaluation is an essential part of machine learning.\"\n    \"I enjoy attending tech conferences.\"\n    \"Learning about big data technologies is exciting.\"\n    \"I love experimenting with neural network architectures.\"\n    \"I find the theory behind machine learning algorithms interesting.\"\n    \"I enjoy visualizing data insights.\"\n    \"Machine learning models can make accurate predictions.\"\n    \"I love the creativity involved in data storytelling.\"\n    \"I find unsupervised learning techniques intriguing.\"\n    \"I enjoy automating tasks with AI.\"\n    \"Learning about AI ethics is important.\"\n    \"I love the problem-solving aspect of machine learning.\"\n    \"I find cloud computing technologies fascinating.\"\n    \"I enjoy using machine learning for real-world applications.\"\n    \"I love experimenting with different data preprocessing techniques.\"\n    \"I find transfer learning to be a powerful approach.\"\n    \"I enjoy working on machine learning projects.\"\n    \"Learning about data privacy is crucial.\"\n    \"I love the innovation happening in the AI field.\"\n    \"I find data visualization tools useful.\"\n    \"I enjoy testing and validating machine learning models.\"\n    \"I love discovering new machine learning applications.\"\n    \"I find ensemble methods to be effective.\"\n    \"I enjoy learning from data.\"\n    \"Machine learning can provide valuable insights.\"\n    \"I love the interdisciplinary nature of AI.\"\n    \"I find recommendation systems interesting.\"\n    \"I enjoy participating in hackathons.\"\n    \"Learning about neural networks is fascinating.\"\n    \"I love the potential of AI to solve complex problems.\"\n    \"I find sentiment analysis intriguing.\"\n    \"I enjoy implementing machine learning algorithms.\"\n    \"I love the excitement of discovering patterns in data.\"\n    \"I find time series analysis challenging.\"\n    \"I enjoy exploring different types of data.\"\n    \"Machine learning is transforming various industries.\"\n    \"I love working on predictive analytics.\"\n    \"I find anomaly detection to be useful.\"\n    \"I enjoy studying the mathematics behind machine learning.\"\n    \"I love the hands-on experience of building models.\"\n    \"I find clustering techniques interesting.\"\n    \"I enjoy exploring open-source machine learning libraries.\"\n    \"Machine learning can automate complex tasks.\"\n    \"I love the flexibility of machine learning models.\"\n    \"I find computer vision applications fascinating.\"\n    \"I enjoy solving real-world problems with AI.\"\n    \"I love the continuous learning aspect of AI.\"\n    \"I find reinforcement learning to be challenging.\"\n    \"I enjoy experimenting with hyperparameter tuning.\"\n    \"Machine learning can improve decision-making processes.\"\n    \"I love the creativity involved in feature selection.\"\n    \"I find generative models to be fascinating.\"\n    \"I enjoy reading about the latest AI advancements.\"\n    \"Machine learning can enhance user experiences.\"\n    \"I love the diversity of machine learning applications.\"\n    \"I find natural language generation intriguing.\"\n    \"I enjoy working with text data.\"\n    \"Machine learning can optimize business processes.\"\n    \"I love the innovation in AI research.\"\n    \"I find the concept of machine learning interpretability interesting.\"\n    \"I enjoy creating machine learning workflows.\"\n    \"Machine learning can uncover hidden patterns.\"\n    \"I love the impact of AI on society.\"\n    \"I find deep reinforcement learning fascinating.\"\n    \"I enjoy developing custom machine learning solutions.\"\n    \"Machine learning can improve customer experiences.\"\n    \"I love the potential of AI in healthcare.\"\n    \"I find the scalability of machine learning models intriguing.\"\n    \"I enjoy applying machine learning to finance.\"\n    \"Machine learning can enhance security measures.\"\n    \"I love the possibilities of AI in creative industries.\"\n    \"I find the ethical implications of AI important.\"\n    \"I enjoy sharing knowledge about machine learning.\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:36:40.649504Z","iopub.execute_input":"2025-06-23T19:36:40.649779Z","iopub.status.idle":"2025-06-23T19:36:40.655988Z","shell.execute_reply.started":"2025-06-23T19:36:40.649752Z","shell.execute_reply":"2025-06-23T19:36:40.655178Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"## Tokenization and preprocessing\n","metadata":{}},{"cell_type":"code","source":"# Tokenization and preprocessing\n\n# Initialize the Tokenizer to convert text into sequences of integers\ntokenizer = Tokenizer()\n\n# Fit the tokenizer on the provided sentences to build the vocabulary\n# Each unique word is assigned a unique integer index\ntokenizer.fit_on_texts(sentences)\n\n# Total number of unique words in the vocabulary plus one for padding\ntotal_words = len(tokenizer.word_index) + 1\n\n# Initialize a list to hold sequences of tokenized words\ninput_sequences = []\n\n# Process each sentence\nfor line in sentences:\n    # Convert the sentence to a sequence of integers based on the tokenizer\n    token_list = tokenizer.texts_to_sequences([line])[0]\n\n    # Generate n-gram sequences from the integer sequence\n    for i in range(1, len(token_list)):\n        n_gram_sequence = token_list[:i+1]  # Create a sequence including up to the i-th word\n        input_sequences.append(n_gram_sequence)  # Add the sequence to the list\n\n# Find the maximum length of sequences\nmax_sequence_len = max([len(x) for x in input_sequences])\n\n# Pad sequences to ensure they are all the same length\n# Padding is added at the beginning of the sequences (pre-padding)\ninput_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:36:44.574839Z","iopub.execute_input":"2025-06-23T19:36:44.575116Z","iopub.status.idle":"2025-06-23T19:36:44.599890Z","shell.execute_reply.started":"2025-06-23T19:36:44.575096Z","shell.execute_reply":"2025-06-23T19:36:44.599098Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"## Data Prepration","metadata":{}},{"cell_type":"code","source":"# Split data into inputs and labels\n\n# Extract input sequences: all elements except the last one\nX = input_sequences[:, :-1]\n\n# Extract labels: the last element of each sequence\ny = input_sequences[:, -1]\n\n# Convert labels to one-hot encoded format\n# This creates a binary matrix representation of the labels with one-hot encoding\n# num_classes is the total number of unique words in the vocabulary\ny = tf.keras.utils.to_categorical(y, num_classes=total_words)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:36:47.235710Z","iopub.execute_input":"2025-06-23T19:36:47.236427Z","iopub.status.idle":"2025-06-23T19:36:47.240589Z","shell.execute_reply.started":"2025-06-23T19:36:47.236402Z","shell.execute_reply":"2025-06-23T19:36:47.239962Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"## Define the LSTM model\n","metadata":{}},{"cell_type":"code","source":"# Define the LSTM model\n\n# Sequential model allows stacking layers in a linear fashion\nmodel = Sequential([\n    # Embedding layer: Converts word indices to dense vectors\n    # Input dimension: total number of words, Output dimension: size of embedding vectors\n    # Input length: length of input sequences (excluding the last word)\n    Embedding(total_words, 10, input_length=max_sequence_len-1),\n\n    # LSTM layer with 30 units\n    # LSTM (Long Short-Term Memory) is a type of RNN that can capture long-term dependencies\n    LSTM(100),\n\n    # Dense output layer with a softmax activation function\n    # Output dimension: total number of words (for multi-class classification)\n    # Softmax activation converts the output to probabilities for each word\n    Dense(total_words, activation='softmax')\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:36:52.084563Z","iopub.execute_input":"2025-06-23T19:36:52.084835Z","iopub.status.idle":"2025-06-23T19:36:52.094974Z","shell.execute_reply.started":"2025-06-23T19:36:52.084816Z","shell.execute_reply":"2025-06-23T19:36:52.094345Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## Compile the LSTM model\n","metadata":{}},{"cell_type":"code","source":"\n# Compile the model\n\n# Compile the model specifies the loss function, optimizer, and evaluation metrics\nmodel.compile(\n    # Loss function: Categorical cross-entropy, used for multi-class classification problems\n    loss='categorical_crossentropy',\n\n    # Optimizer: Adam, an efficient optimization algorithm that adjusts the learning rate during training\n    optimizer='adam',\n\n    # Metrics: Accuracy, to evaluate the model's performance during training and testing\n    metrics=['accuracy']\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:36:54.825811Z","iopub.execute_input":"2025-06-23T19:36:54.826081Z","iopub.status.idle":"2025-06-23T19:36:54.834521Z","shell.execute_reply.started":"2025-06-23T19:36:54.826062Z","shell.execute_reply":"2025-06-23T19:36:54.833922Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"## # Train the LSTM Model\n","metadata":{}},{"cell_type":"code","source":"# Train the model\n\n# Fit the model on the training data\n# X: Input sequences\n# y: One-hot encoded labels\n# epochs: Number of times the model will go through the entire dataset\n# verbose: Controls the verbosity of the output during training (1 for progress bar)\nmodel.fit(X, y, epochs=100, verbose=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:36:55.665849Z","iopub.execute_input":"2025-06-23T19:36:55.666121Z","iopub.status.idle":"2025-06-23T19:38:17.407874Z","shell.execute_reply.started":"2025-06-23T19:36:55.666101Z","shell.execute_reply":"2025-06-23T19:38:17.407315Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.0549 - loss: 5.3513\nEpoch 2/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1000 - loss: 4.7341\nEpoch 3/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1078 - loss: 4.5859\nEpoch 4/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1080 - loss: 4.5433\nEpoch 5/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1054 - loss: 4.5477\nEpoch 6/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1015 - loss: 4.5229\nEpoch 7/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.0911 - loss: 4.5543\nEpoch 8/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1144 - loss: 4.4147\nEpoch 9/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.0877 - loss: 4.5217\nEpoch 10/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.0932 - loss: 4.5579\nEpoch 11/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1385 - loss: 4.3149\nEpoch 12/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1218 - loss: 4.2598\nEpoch 13/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1667 - loss: 4.2038\nEpoch 14/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2017 - loss: 4.0224\nEpoch 15/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2481 - loss: 3.8705\nEpoch 16/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2568 - loss: 3.7414\nEpoch 17/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2778 - loss: 3.7366\nEpoch 18/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2939 - loss: 3.5944\nEpoch 19/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3012 - loss: 3.5525\nEpoch 20/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2679 - loss: 3.4803\nEpoch 21/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2848 - loss: 3.5045\nEpoch 22/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3302 - loss: 3.1969\nEpoch 23/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3268 - loss: 3.2046\nEpoch 24/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3113 - loss: 3.2167\nEpoch 25/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3029 - loss: 3.1767\nEpoch 26/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3131 - loss: 3.0949\nEpoch 27/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3239 - loss: 3.0081\nEpoch 28/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3714 - loss: 2.8346\nEpoch 29/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3760 - loss: 2.7903\nEpoch 30/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3635 - loss: 2.8488\nEpoch 31/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3734 - loss: 2.7619\nEpoch 32/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4026 - loss: 2.6597\nEpoch 33/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3834 - loss: 2.6504\nEpoch 34/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4131 - loss: 2.4699\nEpoch 35/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4102 - loss: 2.5158\nEpoch 36/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4076 - loss: 2.4781\nEpoch 37/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4035 - loss: 2.4839\nEpoch 38/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4072 - loss: 2.3941\nEpoch 39/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4256 - loss: 2.3026\nEpoch 40/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4508 - loss: 2.2275\nEpoch 41/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4763 - loss: 2.1330\nEpoch 42/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4959 - loss: 2.0809\nEpoch 43/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4792 - loss: 2.0798\nEpoch 44/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5143 - loss: 1.9797\nEpoch 45/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5046 - loss: 1.9470\nEpoch 46/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5153 - loss: 1.9225\nEpoch 47/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5371 - loss: 1.8662\nEpoch 48/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5210 - loss: 1.8699\nEpoch 49/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5484 - loss: 1.7480\nEpoch 50/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5482 - loss: 1.7637\nEpoch 51/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5144 - loss: 1.8189\nEpoch 52/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5463 - loss: 1.7163\nEpoch 53/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5937 - loss: 1.5675\nEpoch 54/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5775 - loss: 1.5954\nEpoch 55/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6114 - loss: 1.5475\nEpoch 56/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6278 - loss: 1.5115\nEpoch 57/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6553 - loss: 1.4172\nEpoch 58/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6575 - loss: 1.4485\nEpoch 59/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6668 - loss: 1.3988\nEpoch 60/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7173 - loss: 1.3471\nEpoch 61/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6994 - loss: 1.3196\nEpoch 62/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6991 - loss: 1.3771\nEpoch 63/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7259 - loss: 1.2837\nEpoch 64/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7187 - loss: 1.2375\nEpoch 65/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7587 - loss: 1.2028\nEpoch 66/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7631 - loss: 1.1749\nEpoch 67/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7962 - loss: 1.1343\nEpoch 68/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7820 - loss: 1.1062\nEpoch 69/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8123 - loss: 1.0479\nEpoch 70/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8127 - loss: 1.0401\nEpoch 71/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8365 - loss: 1.0248\nEpoch 72/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8246 - loss: 0.9859\nEpoch 73/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8561 - loss: 0.9220\nEpoch 74/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8523 - loss: 0.8954\nEpoch 75/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8622 - loss: 0.8705\nEpoch 76/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8743 - loss: 0.8539\nEpoch 77/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8904 - loss: 0.8268\nEpoch 78/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8631 - loss: 0.8137\nEpoch 79/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8754 - loss: 0.7920\nEpoch 80/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8997 - loss: 0.7624\nEpoch 81/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9152 - loss: 0.7339\nEpoch 82/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9280 - loss: 0.7332\nEpoch 83/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9104 - loss: 0.7060\nEpoch 84/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9318 - loss: 0.6743\nEpoch 85/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9306 - loss: 0.6727\nEpoch 86/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9361 - loss: 0.6521\nEpoch 87/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9445 - loss: 0.6301\nEpoch 88/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9430 - loss: 0.6137\nEpoch 89/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9574 - loss: 0.6058\nEpoch 90/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9528 - loss: 0.5775\nEpoch 91/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9655 - loss: 0.5569\nEpoch 92/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9710 - loss: 0.5366\nEpoch 93/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9537 - loss: 0.5348\nEpoch 94/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9733 - loss: 0.5201\nEpoch 95/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9773 - loss: 0.4844\nEpoch 96/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9699 - loss: 0.4812\nEpoch 97/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9755 - loss: 0.4614\nEpoch 98/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9863 - loss: 0.4521\nEpoch 99/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9761 - loss: 0.4315\nEpoch 100/100\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9818 - loss: 0.4233\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7bbff44da810>"},"metadata":{}}],"execution_count":31},{"cell_type":"markdown","source":"## Prediction of Next Word","metadata":{}},{"cell_type":"code","source":"# Function to predict the next word(s) given a seed text\ndef predict_next_word(seed_text, next_words=2):\n    # Repeat the prediction process for the specified number of next words\n    for _ in range(next_words):\n        # Convert the seed text into a sequence of integers using the tokenizer\n        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n\n        # Pad the sequence to ensure it matches the input length expected by the model\n        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n\n        # Predict the probabilities of the next word in the sequence\n        predicted = model.predict(token_list, verbose=0)\n\n        # Get the index of the word with the highest probability\n        predicted_word_index = np.argmax(predicted, axis=-1)[0]\n\n        # Retrieve the word corresponding to the predicted index\n        predicted_word = tokenizer.index_word[predicted_word_index]\n\n        # Append the predicted word to the seed text\n        seed_text += \" \" + predicted_word\n\n    # Return the updated seed text with the predicted word(s)\n    return seed_text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:38:24.615293Z","iopub.execute_input":"2025-06-23T19:38:24.615539Z","iopub.status.idle":"2025-06-23T19:38:24.620480Z","shell.execute_reply.started":"2025-06-23T19:38:24.615524Z","shell.execute_reply":"2025-06-23T19:38:24.619761Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# Test prediction\nprint(predict_next_word(\"Machine Learning\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:39:50.622526Z","iopub.execute_input":"2025-06-23T19:39:50.623051Z","iopub.status.idle":"2025-06-23T19:39:50.775072Z","shell.execute_reply.started":"2025-06-23T19:39:50.623025Z","shell.execute_reply":"2025-06-23T19:39:50.774495Z"}},"outputs":[{"name":"stdout","text":"Machine Learning algorithms are\n","output_type":"stream"}],"execution_count":40}]}